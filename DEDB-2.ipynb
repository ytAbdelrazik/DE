{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3JNnyFVuZ5_",
    "outputId": "4fef145b-fd61-4e63-f3bf-e4cd4de0726d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               uri  rank listUri  imageExists  finalWorth  \\\n",
      "0        elon-musk     1     rtb         True  334260.965   \n",
      "1    larry-ellison     2     rtb         True  235255.878   \n",
      "2       jeff-bezos     3     rtb         True  213507.954   \n",
      "3  mark-zuckerberg     4     rtb         True  193464.600   \n",
      "4  bernard-arnault     5     rtb         True  155493.383   \n",
      "\n",
      "                 personName         source          industries  \\\n",
      "0                 Elon Musk  Tesla, SpaceX        [Automotive]   \n",
      "1             Larry Ellison         Oracle        [Technology]   \n",
      "2                Jeff Bezos         Amazon        [Technology]   \n",
      "3           Mark Zuckerberg       Facebook        [Technology]   \n",
      "4  Bernard Arnault & family           LVMH  [Fashion & Retail]   \n",
      "\n",
      "  countryOfCitizenship gender     birthDate    lastName  wealthList  \\\n",
      "0        United States      M  4.691520e+10        Musk       False   \n",
      "1        United States      M -8.007552e+11     Ellison       False   \n",
      "2        United States      M -1.884384e+11       Bezos       False   \n",
      "3        United States      M  4.533408e+11  Zuckerberg       False   \n",
      "4               France      M -6.572448e+11     Arnault       False   \n",
      "\n",
      "    estWorthPrev  familyList  \\\n",
      "0  334260.965387       False   \n",
      "1  235255.878230       False   \n",
      "2  213507.953505       False   \n",
      "3  193464.600010       False   \n",
      "4  155493.383413       False   \n",
      "\n",
      "                                         squareImage  bioSuppress  \n",
      "0  https://specials-images.forbesimg.com/imageser...        False  \n",
      "1  //specials-images.forbesimg.com/imageserve/5e8...        False  \n",
      "2  https://specials-images.forbesimg.com/imageser...        False  \n",
      "3  //specials-images.forbesimg.com/imageserve/5c7...        False  \n",
      "4  //specials-images.forbesimg.com/imageserve/5dc...        False  \n",
      "Data saved to forbes_data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Set the URL\n",
    "url = \"https://www.forbes.com/forbesapi/person/rtb/0/-estWorthPrev/true.json?fields=rank,uri,personName,lastName,gender,source,industries,countryOfCitizenship,birthDate,finalWorth,estWorthPrev,imageExists,squareImage,listUri\"\n",
    "\n",
    "# Step 2: Make a GET request to fetch the data\n",
    "response = requests.get(url)\n",
    "\n",
    "# Step 3: Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()  # Parse JSON\n",
    "\n",
    "# Navigate to the relevant data\n",
    "    person_list = data.get(\"personList\", {}).get(\"personsLists\", [])\n",
    "\n",
    "    # Step 4: Process and store the data\n",
    "    if person_list:\n",
    "        # Convert to a Pandas DataFrame for easier manipulation\n",
    "        df = pd.DataFrame(person_list)\n",
    "        print(df.head())  # Display first few rows\n",
    "\n",
    "        # Optionally save to a CSV file\n",
    "        df.to_csv(\"forbes_data.csv\", index=False)\n",
    "        print(\"Data saved to forbes_data.csv\")\n",
    "    else:\n",
    "        print(\"No person data found in the response.\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P5pCXFmSRHet",
    "outputId": "6b861d8a-07b1-45b6-d8b9-ea0ad308abcf"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Convert 'birthDate' to datetime, handling potential overflow\n",
    "df['birthDate'] = pd.to_datetime(df['birthDate'], unit='ms')\n",
    "\n",
    "# Filter out rows with invalid birthDate (NaT)\n",
    "df = df.dropna(subset=['birthDate'])\n",
    "\n",
    "# Calculate age\n",
    "current_date = datetime.now()\n",
    "df['age'] = df['birthDate'].apply(lambda x: current_date.year - x.year - ((current_date.month, current_date.day) < (x.month, x.day)))\n",
    "\n",
    "# Drop birthDate column\n",
    "df = df.drop('birthDate', axis=1)\n",
    "\n",
    "df = df.drop(['rank', 'finalWorth', 'source','estWorthPrev','squareImage', 'uri', 'imageExists','wealthList','listUri','lastName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPy62lbBQYrl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmHmqHwsS7aS"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTtqSPvuMq5J",
    "outputId": "ec6ba426-0fb3-41a4-cd89-9b5be6f27893"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personName</th>\n",
       "      <th>industries</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>gender</th>\n",
       "      <th>familyList</th>\n",
       "      <th>bioSuppress</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>[Automotive]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>53</td>\n",
       "      <td>University of Pennsylvania(BA, BS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>[Technology]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "      <td>University of Illinois, Urbana-Champaign (no d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>[Technology]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "      <td>Princeton University (BSE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>[Technology]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "      <td>Harvard University (dropped out)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>[Fashion &amp; Retail]</td>\n",
       "      <td>France</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>75</td>\n",
       "      <td>Page not found</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 personName          industries countryOfCitizenship gender  \\\n",
       "0                 Elon Musk        [Automotive]        United States      M   \n",
       "1             Larry Ellison        [Technology]        United States      M   \n",
       "2                Jeff Bezos        [Technology]        United States      M   \n",
       "3           Mark Zuckerberg        [Technology]        United States      M   \n",
       "4  Bernard Arnault & family  [Fashion & Retail]               France      M   \n",
       "\n",
       "   familyList  bioSuppress  age  \\\n",
       "0       False        False   53   \n",
       "1       False        False   80   \n",
       "2       False        False   60   \n",
       "3       False        False   40   \n",
       "4       False        False   75   \n",
       "\n",
       "                                           education  \n",
       "0                 University of Pennsylvania(BA, BS)  \n",
       "1  University of Illinois, Urbana-Champaign (no d...  \n",
       "2                         Princeton University (BSE)  \n",
       "3                   Harvard University (dropped out)  \n",
       "4                                     Page not found  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Function to scrape education details from Wikipedia\n",
    "def scrape_education(person_name):\n",
    "    base_url = \"https://en.wikipedia.org/wiki/\"\n",
    "    url = base_url + quote(person_name.replace(\" \", \"_\"))  # Handle spaces and special characters\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"YourAppName/1.0 (your_email@example.com)\"})\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            infobox = soup.find('table', {'class': 'infobox'})\n",
    "            if infobox:\n",
    "                for row in infobox.find_all('tr'):\n",
    "                    if 'Education' in row.text:\n",
    "                        return row.find('td').text.strip()\n",
    "            return \"Education not found\"\n",
    "        elif response.status_code == 404:\n",
    "            return \"Page not found\"\n",
    "        else:\n",
    "            return f\"Error: {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "# Fetch education details for the first 20 persons and add to the DataFrame\n",
    "df['education'] = df['personName'].apply(scrape_education)\n",
    "\n",
    "# Display the updated limited DataFrame\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSDK0f5LRVKA",
    "outputId": "16632e38-f1ae-483f-f841-49487bf459b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personName</th>\n",
       "      <th>industries</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>gender</th>\n",
       "      <th>familyList</th>\n",
       "      <th>bioSuppress</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>[Automotive]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>[Technology]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>[Technology]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>[Technology]</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        personName    industries countryOfCitizenship gender  familyList  \\\n",
       "0        Elon Musk  [Automotive]        United States      M       False   \n",
       "1    Larry Ellison  [Technology]        United States      M       False   \n",
       "2       Jeff Bezos  [Technology]        United States      M       False   \n",
       "3  Mark Zuckerberg  [Technology]        United States      M       False   \n",
       "\n",
       "   bioSuppress  age  \n",
       "0        False   53  \n",
       "1        False   80  \n",
       "2        False   60  \n",
       "3        False   40  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVYhrjg5NCvl",
    "outputId": "a2709e6c-6166-424b-af3b-c1d700355c4b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define a function to extract all matching education levels, including unfinished degrees\n",
    "def extract_levels(education):\n",
    "    levels_mapping = {\n",
    "        r'\\bBA\\b|\\bBS\\b|\\bBSE\\b|bachelor': 'Bachelor',\n",
    "        r'\\bMA\\b|\\bMS\\b|master': 'Master',\n",
    "        r'\\bPhD\\b|doctorate': 'PhD',\n",
    "        r'high school': 'High School',\n",
    "        r'middle school': 'Middle School',\n",
    "        r'elementary': 'Elementary',\n",
    "        r'college dropout': 'College Dropout',\n",
    "        r\"high school dropout\": 'High School Dropout',\n",
    "        r\"didn’t attend|didn't attend\": 'Didn’t Attend',\n",
    "        r'dropped out': 'Dropped Out',\n",
    "        r'\\bunfinished PhD\\b|incomplete PhD': 'Unfinished PhD',\n",
    "        r'\\bunfinished Master\\b|incomplete Master': 'Unfinished Master',\n",
    "        r'\\bunfinished Bachelor\\b|incomplete Bachelor': 'Unfinished Bachelor',\n",
    "    }\n",
    "\n",
    "    # Find all matches and return as a semicolon-separated string\n",
    "    levels = []\n",
    "    for pattern, level in levels_mapping.items():\n",
    "        if re.search(pattern, education, re.IGNORECASE):\n",
    "            levels.append(level)\n",
    "    return \"; \".join(sorted(set(levels))) if levels else \"Unknown\"\n",
    "\n",
    "# Define a function to extract university names (unchanged)\n",
    "def extract_university(education):\n",
    "    university_patterns = [\n",
    "        r'(?:University of [^\\n,;()]+)',\n",
    "        r'(?:College of [^\\n,;()]+)',\n",
    "        r'(?:[A-Za-z]+ Institute)',\n",
    "        r'(?:[A-Za-z]+ Academy)',\n",
    "        r'(?:[A-Za-z]+ School)',\n",
    "        r'(?:Urbana-Champaign)',\n",
    "        r'(?:[A-Za-z]+ University)'\n",
    "    ]\n",
    "    matches = []\n",
    "    for pattern in university_patterns:\n",
    "        matches.extend(re.findall(pattern, education, re.IGNORECASE))\n",
    "    return \"; \".join(sorted(set(matches))) if matches else \"Not specified\"\n",
    "\n",
    "\n",
    "\n",
    "# Apply the updated functions\n",
    "df['level'] = df['education'].apply(extract_levels)\n",
    "df['university'] = df['education'].apply(extract_university)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j2aihmCrSso6"
   },
   "outputs": [],
   "source": [
    "df=df.drop(['education'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPycw_RcWrQO"
   },
   "outputs": [],
   "source": [
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>Elon Reeve Musk ( 1971-06-28 ) June 28, 1971 (...</td>\n",
       "      <td>University of Pennsylvania ( BA , BS )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>Lawrence Joseph Ellison ( 1944-08-17 ) August ...</td>\n",
       "      <td>University of Illinois, Urbana-Champaign (no d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>Jeffrey Preston Jorgensen ( 1964-01-12 ) Janua...</td>\n",
       "      <td>Princeton University ( BSE )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>Mark Elliot Zuckerberg ( 1984-05-14 ) May 14, ...</td>\n",
       "      <td>Harvard University (dropped out)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>Warren Edward Buffett ( 1930-08-30 ) August 30...</td>\n",
       "      <td>University of Pennsylvania University of Nebra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Larry Page</td>\n",
       "      <td>Lawrence Edward Page ( 1973-03-26 ) March 26, ...</td>\n",
       "      <td>University of Michigan ( BSE ) Stanford Univer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name                                               Born  \\\n",
       "0        Elon Musk  Elon Reeve Musk ( 1971-06-28 ) June 28, 1971 (...   \n",
       "1    Larry Ellison  Lawrence Joseph Ellison ( 1944-08-17 ) August ...   \n",
       "2       Jeff Bezos  Jeffrey Preston Jorgensen ( 1964-01-12 ) Janua...   \n",
       "3  Mark Zuckerberg  Mark Elliot Zuckerberg ( 1984-05-14 ) May 14, ...   \n",
       "4   Warren Buffett  Warren Edward Buffett ( 1930-08-30 ) August 30...   \n",
       "5       Larry Page  Lawrence Edward Page ( 1973-03-26 ) March 26, ...   \n",
       "\n",
       "                                           Education  \n",
       "0             University of Pennsylvania ( BA , BS )  \n",
       "1  University of Illinois, Urbana-Champaign (no d...  \n",
       "2                       Princeton University ( BSE )  \n",
       "3                   Harvard University (dropped out)  \n",
       "4  University of Pennsylvania University of Nebra...  \n",
       "5  University of Michigan ( BSE ) Stanford Univer...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the text file\n",
    "with open('/Users/youssefabdelrazik/Downloads/wikipedia_facts.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into blocks for each person\n",
    "person_blocks = text.split(\"\\n\\n\")  # Assuming each person's data is separated by a blank line\n",
    "\n",
    "# Dictionary to store extracted features\n",
    "data = defaultdict(dict)\n",
    "\n",
    "for block in person_blocks:\n",
    "    # Extract person's name\n",
    "    person_name = re.search(r\"Person: (.+)\", block)\n",
    "    if person_name:\n",
    "        name = person_name.group(1).strip()\n",
    "    else:\n",
    "        continue  # Skip if no person name is found\n",
    "\n",
    "    # Extract 'Born' details\n",
    "    born_match = re.search(r\"Born: (.+)\", block)\n",
    "    if born_match:\n",
    "        data[name]['Born'] = born_match.group(1).strip()\n",
    "\n",
    "    # Extract 'Education' or 'Alma Mater' details\n",
    "    education_match = re.search(r\"(Education|Alma Mater): (.+)\", block)\n",
    "    if education_match:\n",
    "        data[name]['Education'] = education_match.group(2).strip()\n",
    "\n",
    "# Convert the dictionary to a list of dictionaries for pandas\n",
    "data_list = [{\"Name\": person, **features} for person, features in data.items()]\n",
    "\n",
    "# Create a DataFrame\n",
    "bbb = pd.DataFrame(data_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "bbb.to_csv('DATAA.csv', index=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "bbb.head(6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the text file\n",
    "with open('/Users/youssefabdelrazik/Downloads/wikipedia_facts.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Split the text into blocks for each person\n",
    "person_blocks = text.split(\"\\n\\n\")  # Assuming each person's data is separated by a blank line\n",
    "\n",
    "# Dictionary to store extracted features\n",
    "data = defaultdict(dict)\n",
    "\n",
    "for block in person_blocks:\n",
    "    # Extract person's name\n",
    "    person_name = re.search(r\"Person: (.+)\", block)\n",
    "    if person_name:\n",
    "        name = person_name.group(1).strip()\n",
    "    else:\n",
    "        continue  # Skip if no person name is found\n",
    "\n",
    "    # Extract 'Born' details\n",
    "    born_match = re.search(r\"Born: (.+)\", block)\n",
    "    if born_match:\n",
    "        data[name]['Born'] = born_match.group(1).strip()\n",
    "\n",
    "    # Extract 'Alma Mater' details\n",
    "    alma_mater_match = re.search(r\"Alma\\s?mater: (.+)\", block, re.IGNORECASE)\n",
    "    if alma_mater_match:\n",
    "        data[name]['Education'] = alma_mater_match.group(1).strip()\n",
    "\n",
    "\n",
    "\n",
    "data_list = [{\"Name\": person, **features} for person, features in data.items()]\n",
    "\n",
    "# Create a DataFrame\n",
    "bbb3 = pd.DataFrame(data_list)\n",
    "\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "bbb3.head(5)\n",
    "\n",
    "# Save to a CSV file\n",
    "bbb3.to_csv('DATA5.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df4 = pd.merge(df1, df2, on='Name', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Combine 'Education' columns, prioritizing non-null values\n",
    "merged_df4['Education'] = merged_df4['Education_df1'].combine_first(merged_df4['Education_df2'])\n",
    "\n",
    "# Drop the intermediary columns\n",
    "merged_df4 = merged_df4[['Name', 'Education']]\n",
    "\n",
    "# Display the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame 1\n",
    "df1 = pd.read_csv('/Users/youssefabdelrazik/DATAA.csv')\n",
    "# Example DataFrame 2\n",
    "\n",
    "# Merge the two DataFrames on 'Name'\n",
    "\n",
    "\n",
    "df2=pd.read_csv('/Users/youssefabdelrazik/DATA5.csv')\n",
    "\n",
    "\n",
    "\n",
    "merged_df4 = pd.merge(df1, df2, on='Name', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Combine 'Education' columns, prioritizing non-null values\n",
    "merged_df4['Education'] = merged_df4['Education_df1'].combine_first(merged_df4['Education_df2'])\n",
    "\n",
    "# Drop the intermediary columns\n",
    "merged_df4 = merged_df4[['Name', 'Education']]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Jayson Adair</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abigail Johnson</td>\n",
       "      <td>William Smith College ( BA ) Harvard Universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Achal Bakeri</td>\n",
       "      <td>CEPT University University of Southern California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acharya Balkrishna</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name                                          Education\n",
       "0     A. Jayson Adair                                                NaN\n",
       "1     Abigail Johnson  William Smith College ( BA ) Harvard Universit...\n",
       "2        Achal Bakeri  CEPT University University of Southern California\n",
       "3  Acharya Balkrishna                                                NaN"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df4.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df4=merged_df4.dropna()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abigail Johnson</td>\n",
       "      <td>William Smith College ( BA ) Harvard Universit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Achal Bakeri</td>\n",
       "      <td>CEPT University University of Southern California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adam Neumann</td>\n",
       "      <td>Israeli Naval Academy Baruch College</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adebayo Ogunlesi</td>\n",
       "      <td>Lincoln College, Oxford Harvard Law School Har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adi Godrej</td>\n",
       "      <td>St. Xavier's College, Mumbai MIT Sloan School ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name                                          Education\n",
       "1   Abigail Johnson  William Smith College ( BA ) Harvard Universit...\n",
       "2      Achal Bakeri  CEPT University University of Southern California\n",
       "5      Adam Neumann               Israeli Naval Academy Baruch College\n",
       "6  Adebayo Ogunlesi  Lincoln College, Oxford Harvard Law School Har...\n",
       "7        Adi Godrej  St. Xavier's College, Mumbai MIT Sloan School ..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df4.to_csv(\"tetty.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/youssefabdelrazik/forbes_data.csv')\n",
    "from datetime import datetime\n",
    "# Convert 'birthDate' from ms to datetime\n",
    "df['birthDate'] = pd.to_datetime(df['birthDate'], unit='ms')\n",
    "\n",
    "# Extract year from birthdate\n",
    "df['Year'] = df['birthDate'].dt.year\n",
    "\n",
    "# Function to classify the year into early or late era\n",
    "def classify_era(year):\n",
    "    if year >= 1837:  # Only classify years starting from 1837\n",
    "        decade = int(year // 10 * 10)  # Find the decade\n",
    "        if int(year % 10) <= 4:\n",
    "            return f\"Early {decade}s\"\n",
    "        else:\n",
    "            return f\"Late {decade}s\"\n",
    "    else:\n",
    "        return \"Page not found\"\n",
    "\n",
    "# Apply the era classification function\n",
    "df['Era'] = df['Year'].apply(classify_era)\n",
    "\n",
    "# Drop the 'Year' column if not needed\n",
    "df.drop(columns=['Year'], inplace=True)\n",
    "# Drop birthDate column\n",
    "df = df.drop('birthDate', axis=1)\n",
    "\n",
    "df = df.drop(['rank', 'finalWorth', 'source','estWorthPrev','squareImage', 'uri', 'imageExists','wealthList','listUri','lastName'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personName</th>\n",
       "      <th>industries</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>gender</th>\n",
       "      <th>familyList</th>\n",
       "      <th>bioSuppress</th>\n",
       "      <th>Era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>['Automotive']</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Early 1970s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>['Technology']</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Early 1940s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>['Technology']</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Early 1960s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      personName      industries countryOfCitizenship gender  familyList  \\\n",
       "0      Elon Musk  ['Automotive']        United States      M       False   \n",
       "1  Larry Ellison  ['Technology']        United States      M       False   \n",
       "2     Jeff Bezos  ['Technology']        United States      M       False   \n",
       "\n",
       "   bioSuppress          Era  \n",
       "0        False  Early 1970s  \n",
       "1        False  Early 1940s  \n",
       "2        False  Early 1960s  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.drop(['familyList','bioSuppress','industries'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>gender</th>\n",
       "      <th>Era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1970s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1940s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1960s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1980s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>France</td>\n",
       "      <td>M</td>\n",
       "      <td>Late 1940s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name countryOfCitizenship gender          Era\n",
       "0                 Elon Musk        United States      M  Early 1970s\n",
       "1             Larry Ellison        United States      M  Early 1940s\n",
       "2                Jeff Bezos        United States      M  Early 1960s\n",
       "3           Mark Zuckerberg        United States      M  Early 1980s\n",
       "4  Bernard Arnault & family               France      M   Late 1940s"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.rename(columns={'personName': 'Name'}, inplace=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pk/sqlg96515tb9bll0tv9myjkm0000gn/T/ipykernel_22818/773183573.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdfsemi\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_df4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdfsemi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Name'"
     ]
    }
   ],
   "source": [
    "dfsemi= df.merge(merged_df4, on='Name', how='inner')\n",
    "dfsemi.head(4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsemi.to_csv('mmet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>gender</th>\n",
       "      <th>Era</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1970s</td>\n",
       "      <td>University of Pennsylvania ( BA , BS )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1940s</td>\n",
       "      <td>University of Illinois, Urbana-Champaign (no d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1960s</td>\n",
       "      <td>Princeton University ( BSE )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1980s</td>\n",
       "      <td>Harvard University (dropped out)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Warren Buffett</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1930s</td>\n",
       "      <td>University of Pennsylvania University of Nebra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Name countryOfCitizenship gender          Era  \\\n",
       "0           0        Elon Musk        United States      M  Early 1970s   \n",
       "1           1    Larry Ellison        United States      M  Early 1940s   \n",
       "2           2       Jeff Bezos        United States      M  Early 1960s   \n",
       "3           3  Mark Zuckerberg        United States      M  Early 1980s   \n",
       "4           4   Warren Buffett        United States      M  Early 1930s   \n",
       "\n",
       "                                           Education  \n",
       "0             University of Pennsylvania ( BA , BS )  \n",
       "1  University of Illinois, Urbana-Champaign (no d...  \n",
       "2                       Princeton University ( BSE )  \n",
       "3                   Harvard University (dropped out)  \n",
       "4  University of Pennsylvania University of Nebra...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dfsemi=dfsemi.drop(['gdppercapita'],axis=1)\n",
    "dfsemi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Name</th>\n",
       "      <th>countryOfCitizenship</th>\n",
       "      <th>gender</th>\n",
       "      <th>Era</th>\n",
       "      <th>Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1970s</td>\n",
       "      <td>University of Pennsylvania ( BA , BS )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Larry Ellison</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1940s</td>\n",
       "      <td>University of Illinois, Urbana-Champaign (no d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>United States</td>\n",
       "      <td>M</td>\n",
       "      <td>Early 1960s</td>\n",
       "      <td>Princeton University ( BSE )</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           Name countryOfCitizenship gender          Era  \\\n",
       "0           0      Elon Musk        United States      M  Early 1970s   \n",
       "1           1  Larry Ellison        United States      M  Early 1940s   \n",
       "2           2     Jeff Bezos        United States      M  Early 1960s   \n",
       "\n",
       "                                           Education  \n",
       "0             University of Pennsylvania ( BA , BS )  \n",
       "1  University of Illinois, Urbana-Champaign (no d...  \n",
       "2                       Princeton University ( BSE )  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsemi.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Early 1970s' 'Early 1940s' 'Early 1960s' 'Early 1980s' 'Early 1930s'\n",
      " 'Late 1950s' 'Late 1960s' 'Late 1940s' 'Late 1930s' 'Late 1980s'\n",
      " 'Late 1970s' 'Early 1950s' 'Late 1920s' 'Early 1990s' 'Late 1990s'\n",
      " 'Page not found']\n"
     ]
    }
   ],
   "source": [
    "dfsemi=pd.read_csv('/Users/youssefabdelrazik/mmet.csv')\n",
    "\n",
    "#  Filter the rows where countryOfCitizenship is 'United States'\n",
    "dfusa = dfsemi[dfsemi['countryOfCitizenship'] == 'United States']\n",
    "\n",
    "\n",
    "dfusa.shape\n",
    "dfera=dfusa['Era'].unique()\n",
    "print(dfera)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(907, 6)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsemi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_countries = dfsemi['countryOfCitizenship'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsemi['countryOfCitizenship'] = dfsemi['countryOfCitizenship'].replace('Eswatini (Swaziland)', 'Eswatini')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United States' 'India' 'Canada' 'China' 'Italy' 'France' 'Hong Kong'\n",
      " 'Austria' 'Switzerland' 'Brazil' 'Australia' 'Japan' 'Russia' 'Indonesia'\n",
      " 'Germany' 'Philippines' 'Israel' 'Thailand' 'United Kingdom'\n",
      " 'United Arab Emirates' 'Singapore' 'Taiwan' 'Denmark' 'Malaysia'\n",
      " 'Nigeria' 'Spain' 'Sweden' 'Norway' 'New Zealand' 'Czech Republic'\n",
      " 'South Korea' 'Argentina' 'Colombia' 'Egypt' 'Eswatini' 'Ireland'\n",
      " 'Belize' 'Chile' 'Poland' 'Kazakhstan' 'Turkey' 'Monaco' 'Georgia'\n",
      " 'Venezuela' 'Finland' 'Cyprus' 'Vietnam' 'South Africa' 'Greece'\n",
      " 'Lebanon' 'Guernsey' 'Iceland' 'Bulgaria' 'Ukraine' 'Zimbabwe' 'Tanzania'\n",
      " 'Croatia' 'Romania' 'Netherlands' 'Peru' 'St. Kitts and Nevis' 'Hungary']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "distinct_countries = dfsemi['countryOfCitizenship'].unique()\n",
    "print(distinct_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for United States...\n",
      "Scraping data for India...\n",
      "Scraping data for Canada...\n",
      "Scraping data for China...\n",
      "Scraping data for Italy...\n",
      "Scraping data for France...\n",
      "Scraping data for Hong Kong...\n",
      "Scraping data for Austria...\n",
      "Scraping data for Switzerland...\n",
      "Scraping data for Brazil...\n",
      "Scraping data for Australia...\n",
      "Scraping data for Japan...\n",
      "Scraping data for Russia...\n",
      "Scraping data for Indonesia...\n",
      "Scraping data for Germany...\n",
      "Scraping data for Philippines...\n",
      "Scraping data for Israel...\n",
      "Scraping data for Thailand...\n",
      "Scraping data for United Kingdom...\n",
      "Scraping data for United Arab Emirates...\n",
      "Scraping data for Singapore...\n",
      "Scraping data for Taiwan...\n",
      "Scraping data for Denmark...\n",
      "Scraping data for Malaysia...\n",
      "Scraping data for Nigeria...\n",
      "Scraping data for Spain...\n",
      "Scraping data for Sweden...\n",
      "Scraping data for Norway...\n",
      "Scraping data for New Zealand...\n",
      "Scraping data for Czech Republic...\n",
      "Scraping data for South Korea...\n",
      "Scraping data for Argentina...\n",
      "Scraping data for Colombia...\n",
      "Scraping data for Egypt...\n",
      "Scraping data for Eswatini...\n",
      "Error fetching data for Eswatini: 404\n",
      "No data found for Eswatini.\n",
      "Scraping data for Ireland...\n",
      "Scraping data for Belize...\n",
      "Scraping data for Chile...\n",
      "Scraping data for Poland...\n",
      "Scraping data for Kazakhstan...\n",
      "Scraping data for Turkey...\n",
      "Scraping data for Monaco...\n",
      "Scraping data for Georgia...\n",
      "Scraping data for Venezuela...\n",
      "Scraping data for Finland...\n",
      "Scraping data for Cyprus...\n",
      "Scraping data for Vietnam...\n",
      "Scraping data for South Africa...\n",
      "Scraping data for Greece...\n",
      "Scraping data for Lebanon...\n",
      "Scraping data for Guernsey...\n",
      "Error fetching data for Guernsey: 404\n",
      "No data found for Guernsey.\n",
      "Scraping data for Iceland...\n",
      "Scraping data for Bulgaria...\n",
      "Scraping data for Ukraine...\n",
      "Scraping data for Zimbabwe...\n",
      "Scraping data for Tanzania...\n",
      "Scraping data for Croatia...\n",
      "Scraping data for Romania...\n",
      "Scraping data for Netherlands...\n",
      "Scraping data for Peru...\n",
      "Scraping data for St. Kitts and Nevis...\n",
      "Error fetching data for St. Kitts and Nevis: 404\n",
      "No data found for St. Kitts and Nevis.\n",
      "Scraping data for Hungary...\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of countries to scrape\n",
    "countries = [\n",
    "    'United States', 'India', 'Canada', 'China', 'Italy', 'France', 'Hong Kong', \n",
    "    'Austria', 'Switzerland', 'Brazil', 'Australia', 'Japan', 'Russia', 'Indonesia', \n",
    "    'Germany', 'Philippines', 'Israel', 'Thailand', 'United Kingdom', 'United Arab Emirates', \n",
    "    'Singapore', 'Taiwan', 'Denmark', 'Malaysia', 'Nigeria', 'Spain', 'Sweden', 'Norway', \n",
    "    'New Zealand', 'Czech Republic', 'South Korea', 'Argentina', 'Colombia', 'Egypt', \n",
    "    'Eswatini', 'Ireland', 'Belize', 'Chile', 'Poland', 'Kazakhstan', 'Turkey', 'Monaco', \n",
    "    'Georgia', 'Venezuela', 'Finland', 'Cyprus', 'Vietnam', 'South Africa', 'Greece', \n",
    "    'Lebanon', 'Guernsey', 'Iceland', 'Bulgaria', 'Ukraine', 'Zimbabwe', 'Tanzania', 'Croatia', \n",
    "    'Romania', 'Netherlands', 'Peru', 'St. Kitts and Nevis', 'Hungary'\n",
    "]\n",
    "\n",
    "# Function to fetch GDP data for a specific country and year\n",
    "def fetch_gdp_data(country, year=1930):\n",
    "    url = f'https://countryeconomy.com/gdp/{country.replace(\" \", \"-\").lower()}?year={year}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        return soup\n",
    "    else:\n",
    "        print(f\"Error fetching data for {country}: {response.status_code}\")\n",
    "        return None\n",
    "# Function to remove the last line from the text file\n",
    "def remove_last_line(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # If the file has at least one line, remove the last line\n",
    "    if lines:\n",
    "        lines = lines[:-1]\n",
    "\n",
    "    # Re-write the file without the last line\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "        \n",
    "# Function to remove the first 4 lines from the text file\n",
    "def remove_first_n_lines(file_path, n=4):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Skip the first `n` lines\n",
    "    if len(lines) > n:\n",
    "        lines = lines[n:]\n",
    "\n",
    "    # Re-write the file without the first `n` lines\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Loop through each country in the list\n",
    "for country in countries:\n",
    "    print(f\"Scraping data for {country}...\")\n",
    "\n",
    "    # Fetch the GDP data for the country and year 1930\n",
    "    soup = fetch_gdp_data(country)\n",
    "\n",
    "    if soup:\n",
    "        # Open the file in write mode (this will create the file if it doesn't exist)\n",
    "        file_path = f'{country}_gdp_1930.txt'\n",
    "        with open(file_path, 'w') as file:\n",
    "            # Write the year at the top of the file\n",
    "            file.write(f\"GDP Data for {country} ({1930})\\n\\n\")\n",
    "            \n",
    "            # Find the table with the specified classes\n",
    "            table = soup.find('table', class_='table tabledat table-striped table-condensed table-hover')\n",
    "\n",
    "            # Check if the table exists\n",
    "            if table:\n",
    "                # Extract all rows from the table\n",
    "                rows = table.find_all('tr')\n",
    "\n",
    "                # Loop through each row and extract the columns (td)\n",
    "                for row in rows:\n",
    "                    cols = row.find_all('td')  # Extract all table data cells\n",
    "                    cols = [col.text.strip() for col in cols]  # Clean the text (strip unnecessary whitespace)\n",
    "\n",
    "                    if cols:  # Only write rows that contain data\n",
    "                        # Remove any rows where any column ends with 'M' or '%'\n",
    "                        valid_cols = [col for col in cols if not (col.endswith('%') or col.endswith('M'))]\n",
    "                        if valid_cols:  # Write to file only if there are valid columns left\n",
    "                            file.write(f\"Year: {1930}, Data: {valid_cols}\\n\")\n",
    "            \n",
    "            # Now search for the 'numero dol' class within the body of the page\n",
    "            body = soup.find('body')  # Find the <body> tag\n",
    "            if body:\n",
    "                numero_dol_elements = body.find_all(class_='numero dol')  # Search for elements with the 'numero dol' class\n",
    "\n",
    "                if numero_dol_elements:\n",
    "                    for element in numero_dol_elements:\n",
    "                        element_text = element.text.strip()\n",
    "\n",
    "                        # Skip elements that end with '%' or 'M'\n",
    "                        if element_text.endswith('%') or element_text.endswith('M'):\n",
    "                            continue  # Skip this element\n",
    "                        \n",
    "                        # Write the valid elements to the file\n",
    "                        file.write(f\"Found valid 'numero dol' element: {element_text}\\n\")\n",
    "                else:\n",
    "                    file.write(f\" No elements with class 'numero dol' found.\\n\")\n",
    "            else:\n",
    "                file.write(f\"No body found in the page.\\n\")\n",
    "\n",
    "        # After exporting the data, remove the first 4 lines from the file\n",
    "        remove_first_n_lines(file_path, n=6)\n",
    "        remove_last_line(file_path)\n",
    "\n",
    "    else:\n",
    "        print(f\"No data found for {country}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading the CSV file: 'Country Name'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File path\n",
    "file_path = \"/Users/youssefabdelrazik/Downloads/APINY/wrld.csv\"  # Replace with the path to your file\n",
    "\n",
    "# Load the dataset with error handling\n",
    "try:\n",
    "    # Attempt to load CSV with proper handling for bad lines\n",
    "    df = pd.read_csv(file_path, delimiter=',', header=0, on_bad_lines='skip', quotechar='\"')\n",
    "\n",
    "    # Check the first few rows to understand the structure\n",
    "\n",
    "\n",
    "    # Filter data for United States\n",
    "    us_data = df[df['Country Name'] == 'United States']\n",
    "\n",
    "    # Select data from 1970 to 2023\n",
    "    years = [str(year) for year in range(1970, 2024)]\n",
    "    columns_to_keep = ['Country Name', 'Indicator Name'] + years\n",
    "    us_data_filtered = us_data[columns_to_keep]\n",
    "\n",
    "    # Save to a new CSV file\n",
    "    output_file = \"us_gdp_1970_2023.csv\"\n",
    "    us_data_filtered.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered data saved to {output_file}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error reading the CSV file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>...</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>2023</th>\n",
       "      <th>Unnamed: 68</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>United States</td>\n",
       "      <td>2999.864872</td>\n",
       "      <td>3059.160821</td>\n",
       "      <td>3236.013112</td>\n",
       "      <td>3366.36979</td>\n",
       "      <td>3565.31443</td>\n",
       "      <td>3818.288251</td>\n",
       "      <td>4136.308296</td>\n",
       "      <td>4325.959351</td>\n",
       "      <td>4684.588403</td>\n",
       "      <td>...</td>\n",
       "      <td>57040.208214</td>\n",
       "      <td>58206.614193</td>\n",
       "      <td>60322.261424</td>\n",
       "      <td>63201.045848</td>\n",
       "      <td>65548.070785</td>\n",
       "      <td>64317.398913</td>\n",
       "      <td>71055.876194</td>\n",
       "      <td>77246.673883</td>\n",
       "      <td>81695.187071</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Country Name         1960         1961         1962        1963  \\\n",
       "251  United States  2999.864872  3059.160821  3236.013112  3366.36979   \n",
       "\n",
       "           1964         1965         1966         1967         1968  ...  \\\n",
       "251  3565.31443  3818.288251  4136.308296  4325.959351  4684.588403  ...   \n",
       "\n",
       "             2015          2016          2017          2018          2019  \\\n",
       "251  57040.208214  58206.614193  60322.261424  63201.045848  65548.070785   \n",
       "\n",
       "             2020          2021          2022          2023  Unnamed: 68  \n",
       "251  64317.398913  71055.876194  77246.673883  81695.187071          NaN  \n",
       "\n",
       "[1 rows x 66 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfusa=pd.read_csv('/Users/youssefabdelrazik/Downloads/xsx.csv')\n",
    "usa=dfusa[dfusa['Country Name']=='United States']\n",
    "\n",
    "usa=usa.drop(['Country Code','Indicator Name','Indicator Code'],axis=1)\n",
    "usa.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been extracted and saved to Argentina_GDP3.csv.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# File name\n",
    "input_file = \"Argentina_gdp_1930.txt\"\n",
    "output_file = \"Argentina_GDP3.csv\"\n",
    "\n",
    "# Regular expression pattern\n",
    "\n",
    "\n",
    "\n",
    "pattern = r\"Found valid 'numero dol' element: \\$(\\d{1,3}(?:,\\d{3})*)\"\n",
    "\n",
    "\n",
    "# Read the file\n",
    "with open(input_file, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Find all matches using the regular expression\n",
    "matches = re.findall(pattern, data)\n",
    "\n",
    "# Convert matches to a list of GDP values as integers (removing commas)\n",
    "gdp_values = [int(gdp.replace(',', '')) for gdp in matches]\n",
    "\n",
    "# Create a DataFrame with descending years starting from 2023\n",
    "years = list(range(2023, 2023 - len(gdp_values), -1))\n",
    "df = pd.DataFrame({\"Year\": years, \"GDP\": gdp_values})\n",
    "\n",
    "# Save to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data has been extracted and saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# File name\n",
    "input_file = \"Argentina_gdp_1930.txt\"\n",
    "output_file = \"Argentina_GDP3.csv\"\n",
    "\n",
    "# Regular expression pattern\n",
    "\n",
    "\n",
    "\n",
    "pattern = r\"Found valid 'numero dol' element: \\$(\\d{1,3}(?:,\\d{3})*)\"\n",
    "\n",
    "\n",
    "# Read the file\n",
    "with open(input_file, 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "# Find all matches using the regular expression\n",
    "matches = re.findall(pattern, data)\n",
    "\n",
    "# Convert matches to a list of GDP values as integers (removing commas)\n",
    "gdp_values = [int(gdp.replace(',', '')) for gdp in matches]\n",
    "\n",
    "# Create a DataFrame with descending years starting from 2023\n",
    "years = list(range(2023, 2023 - len(gdp_values), -1))\n",
    "df = pd.DataFrame({\"Year\": years, \"GDP\": gdp_values})\n",
    "\n",
    "# Save to a CSV file\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Data has been extracted and saved to {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: ./Eswatini_gdp.csv\n",
      "File not found: ./Guernsey_gdp.csv\n",
      "File not found: ./St._Kitts_and_Nevis_gdp.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[216], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_gdp\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Apply the function to calculate GDP for each row in the DataFrame\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgdp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_average_gdp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcountryOfCitizenship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEra\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Output the resulting DataFrame\u001b[39;00m\n\u001b[1;32m     61\u001b[0m dff\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[216], line 58\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_gdp\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Apply the function to calculate GDP for each row in the DataFrame\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m dff[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgdp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dff\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mcalculate_average_gdp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcountryOfCitizenship\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEra\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Output the resulting DataFrame\u001b[39;00m\n\u001b[1;32m     61\u001b[0m dff\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[216], line 54\u001b[0m, in \u001b[0;36mcalculate_average_gdp\u001b[0;34m(country, era)\u001b[0m\n\u001b[1;32m     51\u001b[0m country_gdp \u001b[38;5;241m=\u001b[39m gdp_data[country]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Filter GDP data for the specified years and calculate the average\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m avg_gdp \u001b[38;5;241m=\u001b[39m country_gdp[\u001b[43mcountry_gdp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misin(years)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGDP\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m avg_gdp\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Year'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load all country-specific GDP CSV files into a dictionary of DataFrames\n",
    "input_directory='./'\n",
    "gdp_data = {}\n",
    "for country in countries:\n",
    "    # Generate the expected filename\n",
    "    filename = f\"{country.replace(' ', '_')}_gdp.csv\"\n",
    "    input_path = os.path.join(input_directory, filename)\n",
    "\n",
    "    # Check if the file exists before loading\n",
    "    if os.path.exists(input_path):\n",
    "        gdp_data[country] = pd.read_csv(input_path)\n",
    "    else:\n",
    "        print(f\"File not found: {input_path}\")\n",
    "    \n",
    "# Example DataFrame\n",
    "# Replace this with your actual DataFrame\n",
    "dff=pd.read_csv('/Users/youssefabdelrazik/mmet.csv')\n",
    "\n",
    "# Define custom era ranges\n",
    "era_ranges = {\n",
    "    \"Early 1930s\": list(range(1930, 1935)),\n",
    "    \"Late 1930s\": list(range(1935, 1940)),\n",
    "    \"Early 1940s\": list(range(1940, 1945)),\n",
    "    \"Late 1940s\": list(range(1945, 1950)),\n",
    "    \"Early 1950s\": list(range(1950, 1955)),\n",
    "    \"Late 1950s\": list(range(1955, 1960)),\n",
    "    \"Early 1960s\": list(range(1960, 1965)),\n",
    "    \"Late 1960s\": list(range(1965, 1970)),\n",
    "    \"Early 1970s\": list(range(1970, 1975)),\n",
    "    \"Late 1970s\": list(range(1975, 1980)),\n",
    "    \"Early 1980s\": list(range(1980, 1985)),\n",
    "    \"Late 1980s\": list(range(1985, 1990)),\n",
    "    \"Early 1990s\": list(range(1990, 1995)),\n",
    "    \"Late 1990s\": list(range(1995, 2000))\n",
    "}\n",
    "\n",
    "# Function to calculate GDP for a given country and Era\n",
    "def calculate_average_gdp(country, era):\n",
    "    if country not in gdp_data:\n",
    "        return None  # Return None if GDP data for the country is not available\n",
    "\n",
    "    # Get the year range for the specified Era\n",
    "    years = era_ranges.get(era)\n",
    "    if not years:\n",
    "        return None  # Return None for unsupported Era values\n",
    "\n",
    "    # Get the country's GDP data\n",
    "    country_gdp = gdp_data[country]\n",
    "\n",
    "    # Filter GDP data for the specified years and calculate the average\n",
    "    avg_gdp = country_gdp[country_gdp[\"Year\"].isin(years)][\"GDP\"].mean()\n",
    "    return avg_gdp\n",
    "\n",
    "# Apply the function to calculate GDP for each row in the DataFrame\n",
    "dff[\"gdp\"] = dff.apply(lambda row: calculate_average_gdp(row[\"countryOfCitizenship\"], row[\"Era\"]), axis=1)\n",
    "\n",
    "# Output the resulting DataFrame\n",
    "dff.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0.1', 'Unnamed: 0', 'Name', 'countryOfCitizenship', 'gender',\n",
      "       'Era', 'Education'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dff.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
